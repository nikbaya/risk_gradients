{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 2.4.3\n",
      "SparkUI available at http://ukbb-nb-1-m.c.ukbb-round2.internal:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.19-c6ec8b76eb26\n",
      "LOGGING: writing to /tmp/foo.log\n"
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "hl.init(log='/tmp/foo.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 'gs://nbaya/risk_gradients/'\n",
    "\n",
    "variant_set = 'qc_pos'\n",
    "maf = 0.05\n",
    "# whether to subset to the intersection of SNPs in the EUR 1KG SNPs suggested by PRScs\n",
    "use_1kg_eur_hm3_snps = True\n",
    "h2 = 0.75\n",
    "pi = 0.001\n",
    "chrom='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 19:39:00 Hail: INFO: Reading table with no type imputation\n",
      "  Loading column 's' as type 'str' (type not specified)\n",
      "  Loading column 'label_100000' as type 'str' (type not specified)\n",
      "  Loading column 'label_50000' as type 'str' (type not specified)\n",
      "  Loading column 'label_20000' as type 'str' (type not specified)\n",
      "  Loading column 'label_10000' as type 'str' (type not specified)\n",
      "  Loading column 'label_5000' as type 'str' (type not specified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt = hl.read_matrix_table(\n",
    "    wd+f'genotypes{(\"\" if chrom is \"all\" else f\".chr{chrom}\")}.all.{variant_set}.maf_{maf}{\".1kg_eur_hm3\" if use_1kg_eur_hm3_snps else \"\"}.mt')\n",
    "\n",
    "n_train = int(300e3)\n",
    "seed = 1\n",
    "train = hl.import_table(\n",
    "    wd+f'iid.sim.train.n_{n_train}.seed_{seed}.tsv.bgz').key_by('s')\n",
    "\n",
    "sim_cols = hl.read_table(\n",
    "    wd+f'sim.cols{(\"\" if chrom is \"all\" else f\".chr{chrom}\")}.all.{variant_set}.maf_{maf}.h2_{h2}.pi_{pi}{\".1kg_eur_hm3\" if use_1kg_eur_hm3_snps else \"\"}.ht')\n",
    "sim = mt.annotate_cols(sim_y=sim_cols[mt.s].y)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_sub = int(5e3)\n",
    "subset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = train.filter(\n",
    "    train[f'label_{n_train_sub}'] == str(subset))\n",
    "sim_sub = sim.filter_cols(hl.is_defined(train_sub[sim.s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "    'isFemale': bool\n",
      "    'age': int32\n",
      "    'age_squared': int32\n",
      "    'age_isFemale': int32\n",
      "    'age_squared_isFemale': int32\n",
      "    'PC1': float64\n",
      "    'PC2': float64\n",
      "    'PC3': float64\n",
      "    'PC4': float64\n",
      "    'PC5': float64\n",
      "    'PC6': float64\n",
      "    'PC7': float64\n",
      "    'PC8': float64\n",
      "    'PC9': float64\n",
      "    'PC10': float64\n",
      "    'PC11': float64\n",
      "    'PC12': float64\n",
      "    'PC13': float64\n",
      "    'PC14': float64\n",
      "    'PC15': float64\n",
      "    'PC16': float64\n",
      "    'PC17': float64\n",
      "    'PC18': float64\n",
      "    'PC19': float64\n",
      "    'PC20': float64\n",
      "    'sim_y': float64\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'varid': str\n",
      "    'A1_1kg': str\n",
      "    'A2_1kg': str\n",
      "    'AF': float64\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'dosage': float64\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sim_sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008856, 5000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_sub.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 18:59:30 Hail: INFO: Number of BGEN files parsed: 22\n",
      "2019-08-27 18:59:30 Hail: INFO: Number of samples in BGEN files: 487409\n",
      "2019-08-27 18:59:30 Hail: INFO: Number of variants across all BGEN files: 93095623\n",
      "2019-08-27 19:01:58 Hail: INFO: Number of BGEN files parsed: 22\n",
      "2019-08-27 19:01:58 Hail: INFO: Number of samples in BGEN files: 487409\n",
      "2019-08-27 19:01:58 Hail: INFO: Number of variants across all BGEN files: 93095623\n"
     ]
    }
   ],
   "source": [
    "variants = hl.read_table('gs://nbaya/split/qc_pos_variants.ht')\n",
    "# variants = variants.annotate(**hl.parse_variant(variants.v))\n",
    "# variants = variants.key_by('locus','alleles') \n",
    "gt0 = hl.import_bgen(path='gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr'+str(set(range(1,23))).replace(' ','')+'_v3.bgen',\n",
    "                     entry_fields=['GT'],\n",
    "                     n_partitions = 1000,\n",
    "                     sample_file = 'gs://ukb31063/ukb31063.autosomes.sample',\n",
    "                     variants=variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'varid': str\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'GT': call\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gt0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_joined = gt0[sim_sub.row_key, sim_sub.col_key]\n",
    "sim_sub1 = sim_sub.annotate_entries(GT=mt_joined.GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "    'isFemale': bool\n",
      "    'age': int32\n",
      "    'age_squared': int32\n",
      "    'age_isFemale': int32\n",
      "    'age_squared_isFemale': int32\n",
      "    'PC1': float64\n",
      "    'PC2': float64\n",
      "    'PC3': float64\n",
      "    'PC4': float64\n",
      "    'PC5': float64\n",
      "    'PC6': float64\n",
      "    'PC7': float64\n",
      "    'PC8': float64\n",
      "    'PC9': float64\n",
      "    'PC10': float64\n",
      "    'PC11': float64\n",
      "    'PC12': float64\n",
      "    'PC13': float64\n",
      "    'PC14': float64\n",
      "    'PC15': float64\n",
      "    'PC16': float64\n",
      "    'PC17': float64\n",
      "    'PC18': float64\n",
      "    'PC19': float64\n",
      "    'PC20': float64\n",
      "    'sim_y': float64\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'varid': str\n",
      "    'A1_1kg': str\n",
      "    'A2_1kg': str\n",
      "    'AF': float64\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'dosage': float64\n",
      "    'GT': call\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sim_sub1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Type:\n",
      "        call\n",
      "--------------------------------------------------------\n",
      "Source:\n",
      "    <hail.matrixtable.MatrixTable object at 0x7f82f24777f0>\n",
      "Index:\n",
      "    ['row', 'column']\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gt0.GT.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 20:43:27 Hail: INFO: merging 5001 files totalling 1.2G...\n",
      "2019-08-27 20:44:18 Hail: INFO: while writing:\n",
      "    gs://nbaya/risk_gradients/sim.5k..all.qc_pos.maf_0.05.1kg_eur_hm3.bed\n",
      "  merge time: 50.720s\n",
      "2019-08-27 20:44:20 Hail: INFO: merging 5000 files totalling 28.7M...\n",
      "2019-08-27 20:44:36 Hail: INFO: while writing:\n",
      "    gs://nbaya/risk_gradients/sim.5k..all.qc_pos.maf_0.05.1kg_eur_hm3.bim\n",
      "  merge time: 16.906s\n",
      "2019-08-27 20:44:38 Hail: INFO: merging 4 files totalling 139.2K...\n",
      "2019-08-27 20:44:38 Hail: INFO: while writing:\n",
      "    gs://nbaya/risk_gradients/sim.5k..all.qc_pos.maf_0.05.1kg_eur_hm3.fam\n",
      "  merge time: 404.393ms\n",
      "2019-08-27 20:44:38 Hail: INFO: wrote 1008856 variants and 5000 samples to 'gs://nbaya/risk_gradients/sim.5k..all.qc_pos.maf_0.05.1kg_eur_hm3'\n"
     ]
    }
   ],
   "source": [
    "hl.export_plink(dataset=sim_sub1,\n",
    "               output=wd+f'sim.5k{(\"\" if chrom is \"all\" else f\".chr{chrom}\")}.all.{variant_set}.maf_{maf}{\".1kg_eur_hm3\" if use_1kg_eur_hm3_snps else \"\"}',\n",
    "               call=sim_sub1.GT,\n",
    "               fam_id='0',\n",
    "               ind_id=sim_sub1.s,\n",
    "               pat_id='0',\n",
    "               mat_id='0',\n",
    "               is_female=sim_sub1.isFemale,\n",
    "               pheno=sim_sub1.sim_y,\n",
    "               varid=sim_sub1.rsid,\n",
    "               cm_position=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sub1 = hl.variant_qc(sim_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sub1 = sim_sub1.rename({'AF':'alt_AF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sub1.rows().export(wd+'sim.rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sub1 = sim_sub1.rename({'A1_maf':'A1_AF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 21:04:15 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-49ea5932aabe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_sub1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'sim.rows.5k.all.qc_pos.maf_0.05.1kg_eur_hm3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m</opt/conda/default/lib/python3.6/site-packages/decorator.py:decorator-gen-996>\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, output, types_file, header, parallel, delimiter)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(__original_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__original_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__original_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m__original_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/default/lib/python3.6/site-packages/hail/table.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, output, types_file, header, parallel, delimiter)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         Env.backend().execute(\n\u001b[1;32m   1014\u001b[0m             TableWrite(self._tir, TableTextWriter(output, types_file, header,\n\u001b[0;32m-> 1015\u001b[0;31m                                                   Env.hail().utils.ExportType.getExportType(parallel), delimiter)))\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnamed_exprs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'GroupedTable'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, ir, timed)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jhc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuteJSON\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtimings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/default/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim_sub1.rows().export(wd+'sim.rows.5k.all.qc_pos.maf_0.05.1kg_eur_hm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 21:19:29 Hail: INFO: Reading table with no type imputation\n",
      "  Loading column 'locus' as type 'str' (type not specified)\n",
      "  Loading column 'alleles' as type 'str' (type not specified)\n",
      "  Loading column 'varid' as type 'str' (type not specified)\n",
      "  Loading column 'rsid' as type 'str' (type not specified)\n",
      "  Loading column 'minor_allele' as type 'str' (type not specified)\n",
      "  Loading column 'maf' as type 'str' (type not specified)\n",
      "  Loading column 'info' as type 'str' (type not specified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = hl.import_table('gs://nbaya/risk_gradients/ukb.maf_info.tsv.bgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = info.annotate(locus=hl.parse_locus(s=info.locus,reference_genome='GRCh37'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sub_rows = sim_sub1.rows().key_by('locus','rsid')\n",
    "info = info.key_by('locus','rsid')\n",
    "info = info.filter(hl.is_defined(sim_sub_rows[info.locus,info.rsid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 21:54:28 Hail: INFO: Finished type imputation\n",
      "  Loading column 'locus' as type 'str' (imputed)\n",
      "  Loading column 'alleles' as type 'str' (imputed)\n",
      "  Loading column 'varid' as type 'str' (imputed)\n",
      "  Loading column 'rsid' as type 'str' (imputed)\n",
      "  Loading column 'minor_allele' as type 'str' (imputed)\n",
      "  Loading column 'maf' as type 'float64' (imputed)\n",
      "  Loading column 'info' as type 'float64' (imputed)\n",
      "2019-08-27 21:54:37 Hail: INFO: Finished type imputation\n",
      "  Loading column 'locus' as type 'str' (imputed)\n",
      "  Loading column 'alleles' as type 'str' (imputed)\n",
      "  Loading column 'varid' as type 'str' (imputed)\n",
      "  Loading column 'rsid' as type 'str' (imputed)\n",
      "  Loading column 'minor_allele' as type 'str' (imputed)\n",
      "  Loading column 'maf' as type 'float64' (imputed)\n",
      "  Loading column 'info' as type 'float64' (imputed)\n",
      "2019-08-27 21:54:52 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2019-08-27 21:55:07 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1010906"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008856, 5000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_sub.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = info.annotate(A1 = sim_sub_rows[info.locus,info.rsid].alleles[0],\n",
    "                     A2 = sim_sub_rows[info.locus,info.rsid].alleles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-27 22:07:00 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2019-08-27 22:07:17 Hail: INFO: Coerced sorted dataset\n",
      "2019-08-27 22:07:21 Hail: INFO: Coerced sorted dataset\n",
      "2019-08-27 22:07:25 Hail: INFO: Coerced sorted dataset\n",
      "2019-08-27 22:07:29 Hail: INFO: Coerced sorted dataset\n",
      "2019-08-27 22:07:34 Hail: INFO: Coerced sorted dataset\n",
      "2019-08-27 22:15:52 Hail: INFO: merging 17 files totalling 19.7M...\n",
      "2019-08-27 22:15:53 Hail: INFO: while writing:\n",
      "    gs://nbaya/risk_gradients/sim.variant_info.all.qc_pos.maf_0.05.1kg_eur_hm3.tsv.gz\n",
      "  merge time: 953.821ms\n"
     ]
    }
   ],
   "source": [
    "info.export(wd+'sim.variant_info.all.qc_pos.maf_0.05.1kg_eur_hm3.tsv.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}